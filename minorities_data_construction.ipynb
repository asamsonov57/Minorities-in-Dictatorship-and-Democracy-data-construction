{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2330e87f-772f-486b-96f1-82d61b5bfa82",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#This is a project that constructs the data I used for my paper \"Minorities in Dictatorship and Democracy\".\n",
    "#The paper investigates the relationship between the government representation \n",
    "#of ethnic minorities and the level of democracy.\n",
    "#While not all the data made it into the paper, I am making the code public because \n",
    "#some data transformation and merging techniques can be useful to other researchers.\n",
    "#In particular, I demonstrate how to transform \n",
    "#the Ethnic Power Relations Dataset (https://icr.ethz.ch/data/epr/core/) and \n",
    "#World Development Indicators (https://databank.worldbank.org/source/world-development-indicators)\n",
    "#into a more user-friendly format that allows for easy analysis. \n",
    "#I also show how to merge cross-country datasets where country names have different spellings \n",
    "#(e.g. \"USA\" and \"United States of America\").\n",
    "#Feel free to contact me at asamsonov94@ucla.edu for any questions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6f9e32-db52-4588-b741-050b161e66b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import packages\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "\n",
    "\n",
    "#Replace the path with the actual directory on your computer.\n",
    "os.chdir(\"/Users/asamsonov94/Desktop/minorities_empirics_2023\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63614c3-3640-4dce-84b2-9ac516966cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The EPR dataset (https://icr.ethz.ch/data/epr/core/)) lists ethnic groups accross the world and several decades and classifies their government representation.\n",
    "#The original dataset is in the following format:\n",
    "#country/ beginning year / end year / ethnic group / group size/ government status / other variables\n",
    "#The code below transforms it into a more usable format needed for my research:\n",
    "#country / year / number of minorities / share of minorities included in government / other variables\n",
    "\n",
    "\n",
    "#Download the EPR dataset (https://icr.ethz.ch/data/epr/core/) in a csv format. Replace the path with the actual file name on your computer.\n",
    "\n",
    "df = pd.read_csv(\"/Users/asamsonov94/Desktop/minorities_empirics_2023/EPR-2021.csv\")\n",
    "\n",
    "#Transform the dataframe into a list of dictionaries where each dictionary is a line in dataframe\n",
    "list_of_dicts = [row.to_dict() for _, row in df.iterrows()]\n",
    "\n",
    "\n",
    "min_year = df['from'].min()\n",
    "max_year = df['to'].max()\n",
    "\n",
    "#Choose which statuses mean that a minority is included\n",
    "included = ['MONOPOLY','DOMINANT','SENIOR PARTNER', 'JUNIOR PARTNER']\n",
    "\n",
    "#Leave only countries with large majorities as in the paper\n",
    "countries_with_large_majorities = set()\n",
    "for dict in list_of_dicts:\n",
    "    if dict[\"size\"] >= 0.5:\n",
    "        countries_with_large_majorities.add(dict[\"statename\"])\n",
    "        \n",
    "for dict in list_of_dicts:\n",
    "    if dict[\"statename\"] not in countries_with_large_majorities:\n",
    "        list_of_dicts.remove(dict)\n",
    "\n",
    "\n",
    "#The function below goes over list of dictionaries that represent original dataframe rows. Ignores if a group is not a minority.\n",
    "#If a group is a minority, computes the number of minorities in a given country-year.\n",
    "#Function outputs a dictionary where key is a tuple (country, year) \n",
    "#and value is a list [number of minorities, number of included minorities]\n",
    "\n",
    "        \n",
    "def check_and_add(year,smalldict,bigdict):\n",
    "    \n",
    "    begin = smalldict[\"from\"]\n",
    "    end = smalldict[\"to\"]\n",
    "    statename = smalldict[\"statename\"]\n",
    "    \n",
    "    if not (begin <= year <= end):\n",
    "        return\n",
    "    if smalldict[\"size\"] >= 0.25:\n",
    "        return\n",
    "    delta_mins = 1\n",
    "    delta_inc_mins = 0\n",
    "    if smalldict[\"status\"] in included:\n",
    "        delta_inc_mins = 1\n",
    "    if not (statename,year) in bigdict:\n",
    "        bigdict[(statename,year)] = [0,0]\n",
    "    bigdict[(statename,year)] = list(np.array([delta_mins,delta_inc_mins]) + np.array(bigdict[(statename,year)]))\n",
    "        \n",
    "bigdict = {}\n",
    "for year in range(min_year, max_year):\n",
    "    for dict in list_of_dicts:\n",
    "        check_and_add(year,dict,bigdict)\n",
    "\n",
    "        \n",
    "#Turn the above dictionary into a list of lists where each list is a row for a future dataframe\n",
    "        \n",
    "data = []\n",
    "for key in bigdict:\n",
    "    lst = list(key) + bigdict[key]\n",
    "    data.append(lst)\n",
    "\n",
    "#Turn the above dictionary into a list of lists where each list is a row for a future dataframe    \n",
    "\n",
    "df1 = pd.DataFrame(data, columns = ['country', 'year','minorities','included_minorities'])\n",
    "\n",
    "#Transform the \"year\" variable into an \"int\" format    \n",
    "\n",
    "for i in range(len(df1)):\n",
    "            df1.loc[i, 'year'] = int(df1.loc[i, 'year'])\n",
    "        \n",
    "#compute the share of included minorities\n",
    "\n",
    "df1['included_minorities_share'] = df1['included_minorities']/df1['minorities']\n",
    "        \n",
    "display(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7396004-01c4-462c-9548-9e24d6b61504",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The code below transforms the World Development Indicators dataset (https://databank.worldbank.org/source/world-development-indicators)\n",
    "#into a more usable format.\n",
    "#The original format is: \n",
    "#country / variable/ variable value in Year1/ variable value in Year2 .../\n",
    "#The resulting dataframe is in the format:\n",
    "#contry/year/variable\n",
    "\n",
    "#Download the WDI dataset (https://databank.worldbank.org/source/world-development-indicators) in a csv format. \n",
    "#Replace the path with the actual file name on your computer.\n",
    "\n",
    "df2 = pd.read_csv(\"/Users/asamsonov94/Desktop/minorities_empirics_2023/wdi_1.csv\")\n",
    "\n",
    "\n",
    "#Remove redundand strings from column names that are years\n",
    "\n",
    "for col_name in df2.columns:\n",
    "    for year in range(1960,2023):\n",
    "        if str(year) in str(col_name):\n",
    "            new_col_name = str(year)\n",
    "            df2.rename(columns={col_name: new_col_name}, inplace=True)\n",
    "            \n",
    "df2.rename(columns={'Country Name': 'country'}, inplace=True)\n",
    "df2.rename(columns={'Series Name': 'series'}, inplace=True)\n",
    "df2 = df2.drop(['Country Code','Series Code'], axis = 1)\n",
    "\n",
    "\n",
    "df2.dropna(subset=['country','series'], inplace=True)\n",
    "\n",
    "\n",
    "#Function returns a dictionary where key is a tuple (country, variable, year) and \n",
    "#value is respective table element. \n",
    "\n",
    "def lookup(df):\n",
    "    years = [col for col in df.columns if len(col) == 4]\n",
    "    dict = {}\n",
    "    for i in range(len(df)):\n",
    "        for year in years:\n",
    "            country = df.loc[i, 'country']\n",
    "            variable = df.loc[i,'series']\n",
    "            dict[(country,variable,year)] = df.loc[i,year]\n",
    "    return dict\n",
    "\n",
    "#Function uses the above dictionary to construct a dataframe.\n",
    "\n",
    "def modify_df(df):\n",
    "\n",
    "    countries = df['country'].unique()\n",
    "    variables = df['series'].unique() \n",
    "    years = [col for col in df.columns if len(col) == 4]\n",
    "    lookup_dict = lookup(df)\n",
    "    list_of_dicts = []\n",
    "      \n",
    "    for country in countries:\n",
    "        for year in years:\n",
    "            dict = {}\n",
    "            dict['country'] = country\n",
    "            dict['year'] = year\n",
    "            for variable in variables:\n",
    "                dict[variable] = lookup_dict[(country,variable,year)]\n",
    "            list_of_dicts.append(dict)\n",
    "            \n",
    "    new_df = pd.DataFrame(list_of_dicts)\n",
    "    return new_df\n",
    "\n",
    "#Apply the function to dataframe\n",
    "\n",
    "df2 = modify_df(df2)\n",
    "\n",
    "#Transform year into int format\n",
    "\n",
    "for i in range(len(df2)):\n",
    "            df2.loc[i, 'year'] = int(df2.loc[i, 'year'])\n",
    "\n",
    "display(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c685f60-1736-4b57-b427-a921e01fc9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The EPR and WDI datasets often have different spelling of the same country (e.g. \"USA\" and \"United States of America\")\n",
    "#The code below harmonizes country names and merges two datasets. The key idea is comparing Wikipedia output for two strings \n",
    "#that might be two names of the same country. The method needs further development, but has a high success rate.\n",
    "\n",
    "#A function that gets the first Wikipedia article based on a search.\n",
    "\n",
    "def get_first_wikipedia_article_url(s):\n",
    "    WIKIPEDIA_API_ENDPOINT = \"https://en.wikipedia.org/w/api.php\"\n",
    "    params = {\n",
    "        \"action\": \"query\",\n",
    "        \"format\": \"json\",\n",
    "        \"list\": \"search\",\n",
    "        \"srsearch\": s,\n",
    "        \"utf8\": 1,\n",
    "        \"formatversion\": 2\n",
    "    }\n",
    "\n",
    "    response = requests.get(WIKIPEDIA_API_ENDPOINT, params=params)\n",
    "    data = response.json()\n",
    "\n",
    "    # Check if search results are present\n",
    "    if not data[\"query\"][\"search\"]:\n",
    "        return None\n",
    "\n",
    "    first_article_title = data[\"query\"][\"search\"][0][\"title\"]\n",
    "    article_url = f\"https://en.wikipedia.org/wiki/{first_article_title.replace(' ', '_')}\"\n",
    "\n",
    "    return article_url\n",
    "\n",
    "\n",
    "#A function that accepts a string s and returns a list. The first element is the first Wikipedia article from search \"s\".\n",
    "#Other entires are search results from substrings of s separated by spaces. \n",
    "\n",
    "\n",
    "def wiki_output(s):\n",
    "    \n",
    "    res = []\n",
    "    res.append(get_first_wikipedia_article_url(s))\n",
    "    if len(s.split()) <= 1:\n",
    "        return res\n",
    "    for word in s.split():\n",
    "        res.append(get_first_wikipedia_article_url(word))   \n",
    "    return res\n",
    "\n",
    "#Score of similarity between string s1 and s2 based on Wikipedia output defined above.\n",
    "\n",
    "def score(s1,s2,dict_of_country_titles):\n",
    "    x = dict_of_country_titles[s1]\n",
    "    y = dict_of_country_titles[s2]\n",
    "    if x[0] == y[0]:\n",
    "        return 1\n",
    "    else:\n",
    "        count = 0\n",
    "        match = 0\n",
    "        for w in x:\n",
    "            for z in y:\n",
    "                count += 1\n",
    "                if w == z:\n",
    "                    match += 1\n",
    "        res = match/count\n",
    "        return res\n",
    "    \n",
    "\n",
    "#A function that matches country lists based on the score function defined above. The result is a dictionary\n",
    "#where keys are country names from one list and values are alternative versions of these country names from \n",
    "#the other list.\n",
    "    \n",
    "def match_country_lists(l1,l2,dict_for_score,f):\n",
    "    dict = {}\n",
    "    l1 = list(l1)\n",
    "    l2 = list(l2)\n",
    "    for x in l1:\n",
    "        match_score = 0\n",
    "        res = None\n",
    "        for y in l2:\n",
    "            new_score = f(x,y,dict_for_score)\n",
    "            if new_score > match_score:\n",
    "                res = y\n",
    "                match_score = new_score\n",
    "        if res != None:\n",
    "            dict[x] = res\n",
    "    key_set = set(dict.keys())\n",
    "    value_set = set(dict.values())\n",
    "    l1 = [x for x in l1 if x not in key_set]\n",
    "    l2 = [x for x in l2 if x not in value_set]\n",
    "    print(l1)\n",
    "    print(\" \")\n",
    "    print(l2)\n",
    "    print(\" \")\n",
    "    return dict\n",
    "\n",
    "#Functions that apply the matching of country lists to merging datasets \n",
    "#with different country spellings.\n",
    "\n",
    "def dfs_to_dict(df1,df2):\n",
    "    countries_in_df1 = df1['country'].unique()\n",
    "    countries_in_df2 = df2['country'].unique()\n",
    "    countries = list(countries_in_df1) +  list(countries_in_df2)\n",
    "    dict_of_country_titles = {}\n",
    "    for country in countries:\n",
    "        dict_of_country_titles[country] = wiki_output(country)\n",
    "    dict = match_country_lists(countries_in_df1,countries_in_df2,dict_of_country_titles,score)\n",
    "    return dict\n",
    "\n",
    "\n",
    "def merge_harmonized_datasets(df1,df2,var1,var2,dict):\n",
    "    for i in range(len(df1)):\n",
    "        if df1.loc[i, var1] in dict:\n",
    "            df1.loc[i, var1] = dict[df1.loc[i, var1]]\n",
    "    merged_df = pd.merge(df1, df2, on=[var1, var2], how='inner')\n",
    "    return merged_df\n",
    "\n",
    "#Creating and correcting a dictionary for specifc datasets I was working with\n",
    "\n",
    "dict  = dfs_to_dict(df1,df2)\n",
    "dict[\"Congo, Democratic Republic of (Zaire)\"] = 'Congo, Dem. Rep.'\n",
    "dict[\"Congo\"] = 'Congo, Rep.'\n",
    "dict[\"Italy/Sardinia\"] = 'Italy'\n",
    "dict[\"Surinam\"] = 'Suriname'\n",
    "dict['Czechoslovakia'] = 'Czechia'\n",
    "\n",
    "\n",
    "\n",
    "df3 = merge_harmonized_datasets(df1,df2,'country','year',dict)\n",
    "display(df3)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
